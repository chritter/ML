{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Learn the basics about notebooks and Apache Spark\n\nThis notebook introduces you to the basics of analytics notebooks and explains what Apache Spark is and how to use Spark in notebooks. The notebook shows you how to load data into the notebook, parse and explore the data, run queries on the data to extract information, plot your analysis results, and save your result in Object Storage.\n\nThis notebooks runs on Python 2 with Spark 2.x, and Object Storage (Swift API).\n\n## Table of contents\n- [What is Apache Spark](#apache_spark)\n- [Get data](#data_set)\n- [Load data](#load_data)\n- [Access data](#access_data)\n- [Add header](#add_header)\n- [Parse data](#parse_data)\n- [Explore data](#explore_data)\n- [Use Spark SQL](#use_spark_sql)\n- [Save results in Object Storage](#save)\n- [Summary](#summary)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"apache_spark\"></a>\n## What is Apache Spark\n\n[Spark](http://spark.apache.org/) is a fast open-source engine for large-scale data processing. It is built for speed and ease of use. Through the advanced DAG execution engine that supports cyclic data flow and in-memory computing, programs can run up to 100 times faster than Hadoop MapReduce in memory, or 10 times faster on disc.\n\nSpark consists of multiple components:\n\n* Spark Core is the underlying computation engine with the fundamental programming abstraction called resilient distributed datasets (RDDs)\n* Spark SQL provides a new data abstraction called DataFrames for structured data processing with SQL and domain-specific language\n* MLlib is a scalable machine learning framework for delivering fast distributed algorithms for mining big data\n* Streaming leverages Spark's fast scheduling capability to perform real-time analysis on streams of new data\n* GraphX is the graph processing framework for the analysis of graph structured data\n\nIn this sample, you will focus on Spark Core and Spark SQL by using the Python API.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"data_set\"></a>\n## Get data\n\nIn the sample, you will use Apache Spark to analyze weather data collected from weather stations in 2017. This data is provided by the NOAA National Climatic Data Center (NCDC).\n\nTo get at the raw data from the NOAA National Climatic Data Center (NCDC):\n\n1. Visit the NCDC site at http://www.ncdc.noaa.gov/data-access/quick-links.\n2. Click **Global Historical Climatology Network-Daily (GHCN-D)**.\n3. Click **GHCN-Daily FTP Access**.\n4. Click the `by_year` folder.\n5. Scroll to the bottom and click **2017.cs.gz** to download the data set.\n6. After the file was downloaded, extract it.\n7. Click **ghcn-daily-by_year-format.rtf** to download additional infromation, e.g. header, for the data set.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "The data in the base file has the following format:\n\n<table border=\"1\" style=\"width:90%\">\n  <tr>\n    <th>STATION</th><th>DATE</th><th>METRIC</th><th>VALUE</th><th>C5</th><th>C6</th><th>C7</th><th>C8</th>\n  </tr>\n  <tr>\n    <td>US1NCBC0113</td><td>20170101</td><td>PRCP</td><td>5</td><td></td><td></td><td>N</td><td></td>\n  </tr>\n  <tr>\n    <td>CA1MB000296</td><td>20170101</td><td>PRCP</td><td>0</td><td></td><td></td><td>N</td><td></td>\n  </tr>\n  <tr>\n    <td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td></td>\n  </tr>\n  <tr>\n    <td>US1MTMH0019</td><td>20170101</td><td>SNOW</td><td>28</td><td></td><td></td><td>N</td><td></td>\n  </tr>\n  <tr>\n    <td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td></td>\n  </tr>\n  <tr>\n    <td>USW00024229</td><td>20170101</td><td>TMAX</td><td>44</td><td></td><td></td><td>W</td><td>2400</td>\n  </tr>\n</table>\n<p>\n\nEach row contains a weather station identifier, a date, a metric which is collected (like precipitation, daily maximum and minimum temperatures, temperature at the time of observation, snowfall, snow depth, and so on) and some additional values.\n\n**Note**: The header is not included in the CSV file and is documented in **ghcn-daily-by_year-format.rtf**. It was added to the table above to provide clarity on what information each column contains.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"load_data\"></a>\n## Load data\nTo load the CSV file to your notebook: \n\n1. Click the **Data** icon on the notebook action bar. \n2. Click on **browse** to add 2017.csv file.\n\nThe data file is now listed on the **Files** tab of the **Data** panel and is stored in Object Storage.\n\n**Note**: Because the CSV file is relatively large, it might take a few minutes to load the data file. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"access_data\"></a>\n## Access data\nBefore you can access data in the data file in the Object Storage, you must setup the Spark configuration with your Object Storage credentials. \n\nTo do this, click on the cell below and select the **Insert to code > Insert Credentials** function from the Files tab below the data file you want to work with.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<div class=\"alert alert-block alert-info\">The credentials object that is created for you is given a generic name. Rename it to `YourCredentials` before you run the cell.</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "source": "Now let's load the data into a `Spark RDD` we will call `weather` by using the `SparkContext`.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 9, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[Row(US1MNHN0184=u'US1MNHN0184', 20170101=u'20170101', PRCP=u'SNOW', 0=u'0', _c4=None, _c5=None, N=u'N', _c7=None),\n Row(US1MNHN0184=u'US1MNHN0184', 20170101=u'20170101', PRCP=u'SNWD', 0=u'274', _c4=None, _c5=None, N=u'N', _c7=None),\n Row(US1MNHN0184=u'US1MNWR0029', 20170101=u'20170101', PRCP=u'PRCP', 0=u'0', _c4=None, _c5=None, N=u'N', _c7=None),\n Row(US1MNHN0184=u'CA1MB000296', 20170101=u'20170101', PRCP=u'PRCP', 0=u'0', _c4=None, _c5=None, N=u'N', _c7=None),\n Row(US1MNHN0184=u'ASN00015643', 20170101=u'20170101', PRCP=u'TMAX', 0=u'274', _c4=None, _c5=None, N=u'a', _c7=None)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "weather = df_data_1"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 12, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[Row(US1MNHN0184=u'US1MNHN0184', 20170101=u'20170101', PRCP=u'SNOW', 0=u'0', _c4=None, _c5=None, N=u'N', _c7=None),\n Row(US1MNHN0184=u'US1MNHN0184', 20170101=u'20170101', PRCP=u'SNWD', 0=u'274', _c4=None, _c5=None, N=u'N', _c7=None),\n Row(US1MNHN0184=u'US1MNWR0029', 20170101=u'20170101', PRCP=u'PRCP', 0=u'0', _c4=None, _c5=None, N=u'N', _c7=None),\n Row(US1MNHN0184=u'CA1MB000296', 20170101=u'20170101', PRCP=u'PRCP', 0=u'0', _c4=None, _c5=None, N=u'N', _c7=None),\n Row(US1MNHN0184=u'ASN00015643', 20170101=u'20170101', PRCP=u'TMAX', 0=u'274', _c4=None, _c5=None, N=u'a', _c7=None)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#import ibmos2spark\n\n#bmos = ibmos2spark.bluemix(sc, YourCredentials, 'learnspark')\n\n#weather = sc.textFile(bmos.url(YourCredentials['container'], '2017.csv'))\nweather.take(5)"
        }, 
        {
            "source": "You can now access the data by using the preconfigured `SparkContext` function in your notebook.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "The RDD you created is a collection of strings corresponding to the individual lines in the raw data file. It is also important to remember that the RDD is defined but not instantiated. By applying an action like `count` to the RDD, you effectively instantiate the RDD.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Total records in the data set: 34061506\n"
                }
            ], 
            "source": "print \"Total records in the data set:\", weather.count()"
        }, 
        {
            "source": "Apply another action to the same RDD that reads the first row of the data.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "The first row in the data set: Row(US1MNHN0184=u'US1MNHN0184', 20170101=u'20170101', PRCP=u'SNOW', 0=u'0', _c4=None, _c5=None, N=u'N', _c7=None)\n"
                }
            ], 
            "source": "print \"The first row in the data set:\", weather.first()"
        }, 
        {
            "source": "<a id=\"add_header\"></a>\n## Add header", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Since the header is not included in the CSV file, it has to be added programmatically.  ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 19, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "['STATION,DATE,METRIC,VALUE,C5,C6,C7,C8',\n Row(US1MNHN0184=u'US1MNHN0184', 20170101=u'20170101', PRCP=u'SNOW', 0=u'0', _c4=None, _c5=None, N=u'N', _c7=None)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "header = sc.parallelize(['STATION,DATE,METRIC,VALUE,C5,C6,C7,C8'])\nunion = header.union(weather.rdd)\nweather = union\nweather.take(2)"
        }, 
        {
            "source": "<a id=\"parse_data\"></a>\n## Parse data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "To really begin working with the data, you need to parse it into columns. You can do this by mapping each line in the RDD to a function that splits the line by commas.\n\nThe lambda notation in Python is used to create anonymous functions, in other words, functions which are not bound to a name. This concept is used in the previous code cell to pass a function as a parameter to the `map` function. The anonymous function receives each line from the `weather` RDD  and splits it at comma boundaries. As a result, the new `weatherParse` RDD is defined as a list of lists. Each list in `weatherParse` corresponds to a line in `weather`, and the strings in each list are the individual elements of the row.", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 20, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "weatherParse = weather.map(lambda line : line.split(\",\"))"
        }, 
        {
            "execution_count": 38, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Pixiedust database opened successfully\nTable VERSION_TRACKER created successfully\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/html": "\n        <div style=\"margin:10px\">\n            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n            </a>\n            <span>Pixiedust version 1.1.7</span>\n        </div>\n        ", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Pixiedust runtime updated. Please restart kernel\nTable SPARK_PACKAGES created successfully\nTable USER_PREFERENCES created successfully\nTable service_connections created successfully\n"
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/html": "<div>Warning: You are not running the latest version of PixieDust. Current is 1.1.7, Latest is 1.1.7.1</div>", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/html": "\n                <div>Please copy and run the following command in a new cell to upgrade: <span style=\"background-color:#ececec;font-family:monospace;padding:0 5px\">!pip install --user --upgrade pixiedust</span></div>\n            ", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "display_data", 
                    "data": {
                        "text/html": "<div>Please restart kernel after upgrading.</div>", 
                        "text/plain": "<IPython.core.display.HTML object>"
                    }, 
                    "metadata": {}
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Spark Job Progress Monitoring cannot be started on DSX\n"
                }
            ], 
            "source": "import pixiedust\npixiedust.enableJobMonitor()\n\n"
        }, 
        {
            "execution_count": 39, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def find_bad_lines(line):\n    return line\n    #try:\n    #    return line.split(\",\")\n    #    \n    #except:\n    #    print('Exception with :',line)\n    #    return [' ']\nweatherParse_test = weather.map(find_bad_lines)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "test =weatherParse_test.collect()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "source": "Run the next cell for a quick look at the first list:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "execution_count": 21, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "['STATION', 'DATE', 'METRIC', 'VALUE', 'C5', 'C6', 'C7', 'C8']"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "weatherParse.first()"
        }, 
        {
            "source": "Now take a look at the individual elements of this first list where the first entry starts at offset zero.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "execution_count": 22, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "'STATION'"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "weatherParse.first()[0]"
        }, 
        {
            "source": "You can also pull elements by index.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 23, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "'METRIC'"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "weatherParse.first()[2]"
        }, 
        {
            "source": "<a id=\"explore_data\"></a>\n## Explore data\nTo better consume the precipitation data, it has to be converted or mapped from one raw form into another format.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Calculate the average precipitation by weather station\nTo calculate the average precipitation that was recorded at each weather station in the data set, reduce the data set by selecting only those rows with precipitation data values, in other words, those rows where the METRIC column equals `PRCP`.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "weatherPrecp = weatherParse.filter(lambda x: x[2] == \"PRCP\")"
        }, 
        {
            "source": "The `weatherPrecp` RDD that you created contains a list of pairs (v1, v2), where v1 is a weather station identifier and v2 is one precipitation data point (one day) for that station. Table 1. depicts this structure.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Table 1.\n\n<table border=1 style=\"width:80%\" align=\"left\">\n  <tr>\n    <th>Key</th><th>Value</th>\n  </tr>\n  <tr>\n    <td>Station 1</td><td>Value 1</td>\n  </tr>\n  <tr>\n    <td>Station 2</td><td>Value 2</td>\n  </tr>\n    <tr>\n    <td>Station 1</td><td>Value 3</td>\n  </tr>\n    <tr>\n    <td>Station 2</td><td>Value 4</td>\n  </tr>\n    <tr>\n    <td>Station 3</td><td>Value 5</td>\n  </tr>\n  <tr>\n    <td>...</td><td>...</td>\n  </tr>\n</table>\n<p>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Next, transform (map) this data set into a new one where each row (data pair) is augmented with the value `1`. Table 2. shows this new structure.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Table 2.\n\n<table border=\"1\" style=\"width:80%\" align=\"left\">\n  <tr>\n    <th>Key</th><th>Value</th>\n  </tr>\n  <tr>\n    <td>Station 1</td><td>(Value 1,1)</td>\n  </tr>\n  <tr>\n    <td>Station 2</td><td>(Value 2,1)</td>\n  </tr>\n    <tr>\n    <td>Station 1</td><td>(Value 3,1)</td>\n  </tr>\n    <tr>\n    <td>Station 2</td><td>(Value 4,1)</td>\n  </tr>\n    <tr>\n    <td>Station 3</td><td>(Value 5,1)</td>\n  </tr>\n  <tr>\n    <td>...</td><td>...</td>\n  </tr>\n</table>\n<p>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "The reason for this mapping is to reduce the table into the form represented by Table 3.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Table 3.\n\n<table border=\"1\" style=\"width:80%\" align=\"left\">\n  <tr>\n    <th>Key</th><th>Value</th>\n  </tr>\n  <tr>\n    <td>Station 1</td><td>(Value 1 + Value 3,2)</td>\n  </tr>\n  <tr>\n    <td>Station 2</td><td>(Value 2 + Value 4,2)</td>\n  </tr>\n    <tr>\n    <td>Station 3</td><td>(Value 5,1)</td>\n  </tr>\n  <tr>\n    <td>...</td><td>...</td>\n  </tr>\n</table>\n<p>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Using this table, you can compute the average precipitation for each station by dividing the summation of the values by the corresponding count.\n\nRun the next code cell to create `weatherPrecpCountByKey`. The outcome is the equivalent to what you see in Table 2.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 25, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# x[0] is the station\n# x[3] is the precipitation value\nweatherPrecpCountByKey = weatherPrecp.map(lambda x : (x[0], (int(x[3]), 1)))"
        }, 
        {
            "source": "The same Python lambda function notation is used to pass a function into the mapping function which transforms `weatherPrecp` into the new RDD. \n\nTo confirm that the mapping produced the expected results, run the next cell:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 26, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "Py4JJavaError", 
                    "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 18.0 failed 10 times, most recent failure: Lost task 1.9 in stage 18.0 (TID 110, yp-spark-dal09-env5-0021, executor b0dbd96f-8b26-4fd1-a838-bbfe53f3c303): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 171, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 166, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 1338, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-20-c95f760dff03>\", line 1, in <lambda>\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1502, in __getattr__\n    raise AttributeError(item)\nAttributeError: split\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.lang.Thread.run(Thread.java:785)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1430)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1429)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1657)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1612)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1601)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat java.lang.Thread.getStackTrace(Thread.java:1117)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:629)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1941)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1954)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1967)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:441)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:785)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 171, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 166, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 1338, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-20-c95f760dff03>\", line 1, in <lambda>\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1502, in __getattr__\n    raise AttributeError(item)\nAttributeError: split\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-26-2a17924afb66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweatherPrecpCountByKey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRDD\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \"\"\"\n\u001b[0;32m-> 1360\u001b[0;31m         \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m         \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n", 
                        "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 18.0 failed 10 times, most recent failure: Lost task 1.9 in stage 18.0 (TID 110, yp-spark-dal09-env5-0021, executor b0dbd96f-8b26-4fd1-a838-bbfe53f3c303): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 171, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 166, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 1338, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-20-c95f760dff03>\", line 1, in <lambda>\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1502, in __getattr__\n    raise AttributeError(item)\nAttributeError: split\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.lang.Thread.run(Thread.java:785)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1430)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1429)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1657)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1612)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1601)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat java.lang.Thread.getStackTrace(Thread.java:1117)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:629)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1941)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1954)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1967)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:441)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:785)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 171, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 166, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 1338, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-20-c95f760dff03>\", line 1, in <lambda>\n  File \"/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1502, in __getattr__\n    raise AttributeError(item)\nAttributeError: split\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:326)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "weatherPrecpCountByKey.first()"
        }, 
        {
            "source": "### Calculate the total precipitation by weather station\n\nTo calculate the total precipitation by weather station, sum (reduce) the precipitation amounts and total readings for every station. Use the `reduceByKey` function for this purpose.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "weatherPrecpAddByKey = weatherPrecpCountByKey.reduceByKey(lambda v1,v2 : (v1[0]+v2[0], v1[1]+v2[1]))"
        }, 
        {
            "source": "Using the `first` function, you can inspect the precipitation values and read the totals for the first station ID. Note that this operation might take some time to complete as the whole chain of RDDs that you created are reinstantiated.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 14, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(u'US1COLR0036', (4315, 363))"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "weatherPrecpAddByKey.first()"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "import sys\r\nimport types\r\nimport pandas as pd\r\nfrom botocore.client import Config\r\nimport ibm_boto3\r\n\r\ndef __iter__(self): return 0\r\n\r\n# @hidden_cell\r\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\r\n# You might want to remove those credentials before you share your notebook.\r\nclient_cfd6857a4f194e3c98225364d85bad45 = ibm_boto3.client(service_name='s3',\r\n    ibm_api_key_id='loMFaVs2IMGcHX6VOhtUOTcoefFcd_jL7A2E7Dvn7HfF',\r\n    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\r\n    config=Config(signature_version='oauth'),\r\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\r\n\r\nbody = client_cfd6857a4f194e3c98225364d85bad45.get_object(Bucket='tests44c734db65ba4a57ba38d34b597e5326',Key='AddressPoints_cleaned_postal.csv')['Body']\r\n# add missing __iter__ method, so pandas accepts body as file-like object\r\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\r\n\r\ndf_data_1 = pd.read_csv(body)\r\ndf_data_1.head()"
                }
            ], 
            "source": "! cat /gpfs/fs01/user/s021-08766e6db051ab-1741987fe625/notebook/work/myfile.py"
        }, 
        {
            "source": "### Compute the average values per station\n\nNow that you have transformed the data into the format you need it in, you can finally compute the average precipitation values per weather station. You create the `weatherAverages` RDD by mapping the `weatherPrecpAddByKey` RDD through a function that divides the precipitation total by the total number of readings.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "weatherAverages = weatherPrecpAddByKey.map(lambda k: (k[0], k[1][0] / float(k[1][1] ) ) )"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 16, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(u'US1COLR0036', 11.887052341597796)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "weatherAverages.first()"
        }, 
        {
            "source": "Now print the first ten stations and their average precipitation values. The station ID is the sort order in the `top` function because it appears first in the tuple (station ID, average precipitation) in the RDD.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Station ZI000067983 had average precipitations of 82.493671\nStation ZI000067975 had average precipitations of 49.165049\nStation ZI000067775 had average precipitations of 67.142857\nStation ZA000067743 had average precipitations of 255.428571\nStation ZA000067475 had average precipitations of 119.000000\nStation WZ004455110 had average precipitations of 55.611111\nStation WQW00041606 had average precipitations of 61.218750\nStation WIM00060096 had average precipitations of 10.555556\nStation WFM00091754 had average precipitations of 108.035714\nStation WF000917530 had average precipitations of 100.651099\n"
                }
            ], 
            "source": "for pair in weatherAverages.top(10):\n    print \"Station %s had average precipitations of %f\" % (pair[0],pair[1])"
        }, 
        {
            "source": "If you want to output the ten weather stations with the highest average precipitation, you need to reverse the order of the tuple to (average precipitation, station ID). You can do this with a `map` function that switches the pair order.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Station US1TXMNG018 had average precipitations of 2809.000000\nStation US1TXFB0025 had average precipitations of 2161.500000\nStation US1MOCY0024 had average precipitations of 2009.000000\nStation US1ILDP0144 had average precipitations of 1808.000000\nStation US1MOJH0005 had average precipitations of 1803.500000\nStation US1TXJJ0003 had average precipitations of 1489.750000\nStation US1NCCL0021 had average precipitations of 1448.000000\nStation US1TNMT0049 had average precipitations of 1361.000000\nStation US1TXWK0011 had average precipitations of 1346.200000\nStation US1FLBW0046 had average precipitations of 1333.666667\n"
                }
            ], 
            "source": "precTop10=[]\nstationsTop10=[]\nfor pair in weatherAverages.map(lambda (x,y) : (y,x)).top(10):\n    precTop10.append(pair[0])\n    stationsTop10.append(pair[1])\n    print \"Station %s had average precipitations of %f\" % (pair[1],pair[0])"
        }, 
        {
            "source": "Plot your results.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAFYCAYAAABEYxtOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7f44fe3ee750>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nN = 10\nindex = np.arange(N)  \nbar_width = 0.5\n\nplt.bar(index, precTop10, bar_width,\n                 color='b')\nplt.xlabel('Stations')\nplt.ylabel('Precipitations')\nplt.title('10 stations with the highest average precipitation')\nplt.xticks(index + bar_width, stationsTop10, rotation=90)\nplt.show()"
        }, 
        {
            "source": "<a id=\"use_spark_sql\"></a>\n## Use Spark SQL\n\n`Spark SQL` lets you query structured data, for example, data in a relational table and can be a very powerful tool for performing complex aggregations.\n\nTo create a relational table that you can query using `Spark SQL` and fill it with snowfall data, you'll use the `Row` class from the `pyspark.sql` package. You will use every line in the `weatherSnow` RDD to create a row object. Each of the row's attributes will be used to access the value of each column.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "To filter the weather data to show only those weather stations that contain the keyword SNOW, you need to reduce the data set to lines with SNOW in the third column. To do this, run the following commands:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 20, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 20, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "4185631"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "weatherSnow = weatherParse.filter(lambda x: x[2]==\"SNOW\")\nweatherSnow.count()"
        }, 
        {
            "source": "The next commands convert each line of the `weatherSnow` RDD into a row object, infer and apply a schema to an RDD of row objects, and register the table name `snow2017`.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from datetime import datetime\nfrom pyspark.sql import Row\nspark = SparkSession.builder.getOrCreate()\n\n# Convert each line of snowWeather RDD into a Row object\nsnowRows= weatherSnow.map(lambda p: Row(station=p[0], month=datetime.strptime(p[1], '%Y%m%d').month, date=datetime.strptime(p[1], '%Y%m%d').day,metric=p[2], value=int(p[3])))\n# Apply Row schema\nsnowSchema = spark.createDataFrame(snowRows)\n# Register 'snow2017' table with 5 columns: station, month, date, metric, and value\nsnowSchema.registerTempTable(\"snow2017\")"
        }, 
        {
            "source": "### Compare the number of snow days between two stations\n\nIn this section, you'll calculate the number of snow days for each month of the year at the `US10chey021` \nand `USW00094985` weather stations. With that information, you'll plot a bar chart to compare the number of snow days for each month at the two stations.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "First, find out on how many days of every month it snowed at the `US10chey021` weather station:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "snow_US10chey021 = spark.sql(\"SELECT month, COUNT(*) AS snowdays FROM snow2017 WHERE station='US10chey021' GROUP BY month ORDER BY month\").collect()"
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[28, 27, 21, 19, 10, 0, 0, 0, 0, 2, 1, 1]\n"
                }
            ], 
            "source": "US10chey021_snowdays_y=[0] * 12\nfor row in snow_US10chey021:\n    US10chey021_snowdays_y[row.month - 1]=row.snowdays\n    \nprint US10chey021_snowdays_y"
        }, 
        {
            "source": "Next, find out how many days of every month it snowed at the `USW00094985` weather station and plot the results:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "snow_USW00094985 = spark.sql(\"SELECT  month, COUNT(*) AS snowdays FROM snow2017 WHERE station='USW00094985' GROUP BY month ORDER BY month\").collect()"
        }, 
        {
            "execution_count": 25, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[25, 24, 22, 29, 31, 30, 31, 31, 30, 31, 30, 26]\n"
                }
            ], 
            "source": "USW00094985_snowdays_y=[0] * 12\nfor row in snow_USW00094985:\n    USW00094985_snowdays_y[row.month -1]=row.snowdays\n    \nprint USW00094985_snowdays_y"
        }, 
        {
            "execution_count": 26, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "display_data", 
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n", 
                        "text/plain": "<matplotlib.figure.Figure at 0x7f44bfad6f90>"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "%matplotlib inline\nimport matplotlib\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nN=12\nind=np.arange(N)\nwidth = 0.35\npUS10chey021 = plt.bar(ind, US10chey021_snowdays_y, width, color='g', label='US10chey021')\npUSW00094985 = plt.bar(ind+width, USW00094985_snowdays_y, width, color='y', label='USW00094985')\n\nplt.ylabel('SNOW DAYS')\nplt.xlabel('MONTH')\nplt.title('Snow Days in 2017 at Stations US10chey021 vs. USW00094985')\nplt.xticks(ind+width, ('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'))\nplt.legend()\n\nplt.show()"
        }, 
        {
            "source": "### Determine the number of snow days at each US weather station\nTo determine how many snow days there were at each of the US weather stations in 2017, run the following command to query the `snow2017` table, using the `COUNT(*)` function to get the total snow days. The table is sorted by station name and limited to only 100 stations.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 27, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "snowStations = spark.sql(\"SELECT  station, COUNT(*) AS snowdays FROM snow2017 WHERE station LIKE 'US%' GROUP BY station ORDER BY station LIMIT 100\")"
        }, 
        {
            "source": "Now print the first 5 rows of the `snowStations` table, including the station name and number of snow days at that station:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 28, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 28, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[Row(station=u'US10adam001', snowdays=1),\n Row(station=u'US10adam002', snowdays=26),\n Row(station=u'US10adam004', snowdays=101),\n Row(station=u'US10adam008', snowdays=1),\n Row(station=u'US10adam010', snowdays=1)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "snowStations.head(5)"
        }, 
        {
            "source": "### Save the query results into a new table", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In this step, you will save the query result of the above `SELECT` query in a new table called `snowdays_2017`. The new table has two columns: STATION (name of station) and SNOWDAYS (number of snow days at the station). ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 29, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "snowStations.registerTempTable('snowdays_2017')"
        }, 
        {
            "source": "Output the five stations with the highest number of snow days in 2017:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 30, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Row(station=u'US10adam056', snowdays=323)\nRow(station=u'US10dawe026', snowdays=176)\nRow(station=u'US10cust015', snowdays=114)\nRow(station=u'US10chey019', snowdays=112)\nRow(station=u'US10daws001', snowdays=111)\n"
                }
            ], 
            "source": "snowStations_new = spark.sql(\"SELECT station, snowdays FROM snowdays_2017 ORDER BY snowdays DESC LIMIT 5\").collect()\nfor row in snowStations_new:\n    print row"
        }, 
        {
            "source": "### Identify the stations with the same number of snow days in 2017\n\nIn this section, you'll identify the stations that had the same number of snow days in 2017. First, you need to query the table `snowdays_2017` again. \n\nThen, by using the `map` function, you'll transform each row into a key-value pair where the key is the number of snow days and the value is the station name.\n\nNext, you'll apply the `reduceByKey` function to each pair, and the value of those pairs that have the same key are concatenated. As a result, the RDD contains the number of snow days, and the list of all stations that have the same number of snow days.\n\nThe `for` loop prints the number of snow days, and the list of stations that have that number of snow days in 2017.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 31, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Snow days:1 Stations:US10adam001,US10adam008,US10adam010,US10blai004,US10buff019,US10burt002,US10cher008,US10cher018,US10cher024,US10cher026,US10chey005,US10chey007,US10chey010,US10chey049,US10chey053,US10chey060,US10clay009,US10colf001,US10cust003,US10cust040,US10cust041,US10dawe017\nSnow days:2 Stations:US10butl020,US10chas034,US10chey028,US10cust042\nSnow days:3 Stations:US10adam035,US10buff007\nSnow days:4 Stations:US10bann009,US10butl005,US10ceda009,US10cumi008,US10cust035\nSnow days:5 Stations:US10chas012,US10chey033,US10cumi003\nSnow days:6 Stations:US10chas016\nSnow days:7 Stations:US10clay041,US10cust005\nSnow days:8 Stations:US10boon010,US10clay008,US10colf002\nSnow days:9 Stations:US10adam036,US10cher016,US10cust032,US10dako003\nSnow days:10 Stations:US10buff004,US10chas011,US10clay029\nSnow days:11 Stations:US10butl011\nSnow days:12 Stations:US10buff039,US10cass005\nSnow days:14 Stations:US10butl008,US10ceda006,US10clay004\nSnow days:15 Stations:US10cust045\nSnow days:19 Stations:US10box_024,US10dako002\nSnow days:23 Stations:US10buff002\nSnow days:26 Stations:US10adam002\nSnow days:28 Stations:US10chey002\nSnow days:29 Stations:US10cumi012,US10cust046\nSnow days:30 Stations:US10chas003\nSnow days:32 Stations:US10chas001\nSnow days:33 Stations:US10adam019\nSnow days:34 Stations:US10clay039\nSnow days:40 Stations:US10chas036\nSnow days:44 Stations:US10adam022\nSnow days:176 Stations:US10dawe026\nSnow days:49 Stations:US10box_014\nSnow days:50 Stations:US10buff006\nSnow days:52 Stations:US10ceda002\nSnow days:53 Stations:US10ceda005\nSnow days:62 Stations:US10cass001\nSnow days:323 Stations:US10adam056\nSnow days:72 Stations:US10box_013\nSnow days:73 Stations:US10box_001\nSnow days:82 Stations:US10cust020\nSnow days:83 Stations:US10cust021\nSnow days:84 Stations:US10chey016\nSnow days:86 Stations:US10chey037\nSnow days:88 Stations:US10dawe015\nSnow days:90 Stations:US10chas002,US10chas028\nSnow days:92 Stations:US10dawe030\nSnow days:93 Stations:US10cust039\nSnow days:94 Stations:US10adam032,US10cust014\nSnow days:95 Stations:US10adam051\nSnow days:96 Stations:US10boon005\nSnow days:101 Stations:US10adam004\nSnow days:102 Stations:US10buff008\nSnow days:106 Stations:US10buff036\nSnow days:108 Stations:US10cust022\nSnow days:109 Stations:US10chey021,US10daws002\nSnow days:111 Stations:US10daws001\nSnow days:112 Stations:US10chey019\nSnow days:114 Stations:US10cust015\n"
                }
            ], 
            "source": "snowdays_100 = spark.sql(\"SELECT station, snowdays FROM snowdays_2017\")\nsnowday_stations=snowdays_100.rdd.map(lambda x:  (x.snowdays,x.station)).reduceByKey(lambda x, y: x + ',' + y)\nfor snowday in snowday_stations.collect():\n    print 'Snow days:' + str(snowday[0]) + ' Stations:' + str(snowday[1])"
        }, 
        {
            "source": "<a id=\"save\"></a>\n## Save results in Object Storage\n\nIn this section, you'll save the `snowStations` DataFrame, which is the query result of the `snow2017` table for 100 US weather stations in Object Storage. Each row contains the name of the weather station and the number of snow days at that station.\n\nThe data will be saved in [Apache Parquet](https://parquet.apache.org/documentation/latest/) file format, which saves data as columns.\n\nEach project you create has a container in your object storage. The name of the container is the same as the project name, minus any blank spaces. You can get the name of the container a couple of different ways: (1) from the **Settings** page of the project, and (2) using `YourCredentials['container']` variable that is generated from the **Insert Credentials** function.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 32, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Save as parquet file \n\n# If you are running this cell multiple times, you will need to overwrite the data in the parquet file:\n#     snowStations.write.mode('overwrite').parquet(bmos.url('CONTAINER', 'snowStations.parquet'))\n\nsnowStations.write.parquet(bmos.url(YourCredentials['container'], 'snowStations.parquet'))"
        }, 
        {
            "source": "After the DataFrame has been saved to Object Storage, you will see a new data source called `snowStations.parquet` in the `Data` pane. \n\nChange the string `CONTAINER` in the following code cell as well and run the cell to read the parquet file and register it as a table again. Once the parquet file is read, you can use the domain-specific language to access the data. When you register the resulting DataFrame as TempTable, you can run SQL queries on the data as well.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 33, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "parquetFile = spark.read.parquet(bmos.url(YourCredentials['container'], 'snowStations.parquet'))\nparquetFile.registerTempTable(\"snow_from_parquet\")"
        }, 
        {
            "source": "<a id=\"summary\"></a>\n## Summary\n\nIn this sample, you learned how to use Apache Spark, how to use PySpark, the Python API for Spark and the matplotlib plotting library. You also learned how to load data from Object Storage as an RDD, how to define Spark data schemas, and how to save intermediate results in parquet format.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id=\"resources\"></a>\n### Resources\n- [Apache Spark 2.1.0 Programming Guide](https://spark.apache.org/docs/2.1.0/programming-guide.html)\n- [Apache Spark 2.1.0 SQL and DataFrames](https://spark.apache.org/docs/2.1.0/sql-programming-guide.html)\n- [PySpark 2.1.0 - Python API for Spark](https://spark.apache.org/docs/2.1.0/api/python)", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "### Author\nSven Hafeneger is a member of the Data Science Experience development team at IBM in Germany. He holds a M.Sc. in Bioinformatics and is passionate about data analysis, machine learning and the Python ecosystem for data science. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<hr>\nCopyright \u00a9 IBM Corp. 2016, 2018. This notebook and its source code are released under the terms of the MIT License.", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }, 
        "name": "cds_ax_spark.ipynb"
    }, 
    "nbformat": 4
}